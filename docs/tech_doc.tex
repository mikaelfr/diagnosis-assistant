\documentclass{article}

\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{enumitem}

\title{Pre-hospital Diagnosis Assistant - Technical Documentation}
\author{Mikael Fredriksson, Simo M{\"a}kel{\"a}, Karine Heinonen}
\date{October 2021}

\begin{document}
\maketitle

\section{Introduction}
Paramedics are frequently the first point of contact for patients with urgent care needs, setting off the patient's clinical pathway through the healthcare system. It can be argued that successful clinical decision-making is of vital importance, as the consequences of incorrect decisions can be catastrophic for the patient as well as the provider. (Paramedic Practice 2021.)

The prehospital environment is characterized by limited diagnostic resources and oftentimes complex care needs. The medical records and information required for on-scene clinical reasoning may be unavailable or incomplete. Nevertheless, an emergency care setting involves a pressure for time critical decision-making.

Human biases, varying levels of provider education and fatigue are among factors that can affect the accuracy of preliminary diagnoses. In this work, we present a technological solution to aid the provider in detection of physiological disturbances and to recognize patients at risk in light of the simple measurements and clinical observations available in pre-hospital care.

The data-driven solution introduced here should be integrated into the patient information system in use. A classification algorithm works in the background and updates its suggested preliminary diagnoses as the crew examines the patient and data is entered into the system. This will not impact provider workload, since the same data would be documented in any case. The provider may use the algorithm-provided information to support their decision on the choice of correct clinical protocol and course of action.

\subsection{Data}

At the early stage of development, real patient data is impossible to obtain. For the initial implementation, we will generate synthetic data by making the physiological parameters deviate from healthy reference values in a manner typically encountered in the clinical setting. Data synthesis is not arbitrary, since medical research, textbooks and clinical experience will be utilized to aim for a data set roughly representing the population actually encountered by emergency medical services.

An argument for the applicability of synthetic data are the simulated scenarios used in provider training and education, which similarly employ artificial clinical parameters to test the student's clinical reasoning skills.

The main challenge in data synthesis is obviously ensuring that the generated data be as representative of the actual population as possible. Achieving this requires substantial medical expertise, which is not available within the scope of this mini-project. Therefore, the data synthesis method should be parametrized such as to provide a mechanism for later adjustments motivated by scientific data and the knowledge of medical practitioners.

The normal ranges of vital signs and other physiological parameters are generally known. The generation of a simulated patient case starts by labeling the case with the pathology being simulated. Then, the numerical physiological parameters are randomly generated by skewing or otherwise offsetting the distribution from the normal range, according to the pathology chosen. The parameters that determine this deviation (e.g. distribution, mean, skewness, etc.) should be easily adjustable to later improve data accuracy. The non-numerical clinical observations will also be assigned randomly, by using as probabilities the actual incidence reported in medical literature. We will start with a very limited number of labels and parameters to achieve a minimum viable implementation.

\section{Methods}

\subsection{Data generation}
Since the medical data of patients is a closely guarded secret, there was obviously no way for us to be granted access to this data. Finding synthetic data was also very difficult, especially in 2021 when most medical datasets were all about COVID. While we did eventually manage to find a dataset of a lot of anonymized EMS data, whether that contained any useful data was a mystery. Not to mention getting the data required going through an application process and after that getting 160gb of data mailed to you on a USB stick. Slightly beyond the scope of this mini-project.

Thus the only option left was to generate our own data. Luckily Simo M{\"a}kel{\"a} is very knowledgeable in the field and was able to spec what needed to be done for the rest of the team.

The first method we tried, was to generate all the vital signs first using a normal distribution and then assigning diagnoses to suitable deviations. This turned out to not work too well. The distributions between diagnoses was pretty bad, some diagnoses were abundant and there were barely any (sometimes none) rows for other diagnoses. This method is called \texttt{generate\_people} in the code.

The second method we tried, and are still using, was to generate healthy people and each diagnosis separately. We take a healthy person and push the values to wanted directions to achieve the symptoms of a specified diagnosis. We also add some randomness, like missing values and diagnoses slightly differing from the actual values occasionally. This method is called \texttt{generate\_people2} in the code.

All data generation code can be found in a file called \texttt{patient\_generator.py}.

\subsection{Building the model}
We originally just used a default \texttt{RandomForestClassifier} from \texttt{scikit}. This worked fine and gave us an accuracy of around 85\%. The mean confidence for wrong classification was around 60\% and for correct ones around 90\%. Since we show in the UI a list of all diagnoses and their probabilities, seeing 60\% confidence tells the user to not trust this particular prediction too much.

We ran into a problem when trying to optimize the model with TPOT. In the first iteration we used \texttt{generate\_people} to generate a list of patients and that list was randomized by default. When we switched to using \texttt{generate\_people2} all of the healthy people were in the train set and pretty much only people with diagnoses were in the test set. Thus we overfit the data pretty hard for the training set and the test set accuracy was hovering a bit under 90\%. Not bad, but way lower than what TPOT was claiming to have gotten for the training set. Shuffling the data set before training was a simple solution for this issue. After shuffling using TPOT to optimize the pipeline, we were able to get the accuracy to around 94\% for the test set.

The code for running the classifier pipeline can be found in a file called \texttt{pipeline.py} and the actual classification code and some data cleanup + preparation can be found in a file called \texttt{classifier.py}.

\section{Visualization}
Very early on Karine Heinonen found a service called \texttt{Streamlit} which turned out to be excellent for our purposes. That allowed us to very easily deploy and display visualization straight from python code. It also allowed great interactivity with users and ourselves as well. It was much easier to just update the pages in the Streamlit app for debugging purposes. It was invaluable for debugging both generation functions quickly. 

The Streamlit app can be found in \texttt{streamlit\_app.py}.

\section{Results and discussion}
We have created a demoable, minimum viable implementation as a proof-of-concept. The system can successfully find a differential diagnosis in the most straightforward cases. We realize, that in its current state, the product's operation is quite simplistic. A similar behaviour could probably be achieved by programming a basic branching logic. As more parameters are added and the data generating process gets expanded with more evidence-based information on incidence of findings connected to different pathologies, we expect to see nonlinearity and interaction terms arise in the data. This is where the machine learning aspect of our product comes to shine. We are confidentthat this line of development will result in a useful tool to assist the clinical provider in dealing with uncertainty.

\end{document}

